---
layout: post
title: "机器学习——基础知识0x1"
date: 2019-2-13 11:34 +200
---


<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

> 此文是在实习期间做读书分享时，总结出来的一篇读书心得，主要参考书籍《机器学习》(周志华)《统计学习方法》(李航)，以及Ng的视频machine learning。内容为线性模型相关。作为入门读物，只需要有高数，线代和概率论的基础即可。

## 机器学习并非魔法

这一章节，个人认为是作为初学者必须要了解的，也就是机器学习并非是多么智能或者魔法般的存在，在一定层面上讲，它就是一个通过数学方法来统计数据规律，然后预测新数据的一门学科。当我们使用机器学习去解决某些问题时，从某些角度来说，就是人为的寻找一个合适的数学方法去统计数据，由于统计的过程计算量太大，因此交由机器完成。哪怕对目前来说，有许多方法与研究已经发展到可以让机器来自动选择合适的数学方法了，但追根溯源，其本质还是一样。

## 基础例子

从最经典的例子出发：若有一组数据\\((x\_1,y\_1), (x\_2,y\_2) ... (x\_n,y\_n)\\)，其中\\(x\_i\\)表示房子面积，\\(y\_i\\)表示房价，让你通过这组数据，找到房价与房子面积的关系，以用来预测其他房子的价格。数据如图所示：

![](/assets/post_picture/1.png)

这道题给如今的初中生来猜测，大概率也会被猜测为一个\\(y = ax + b \\)的一元一次方程，给高中生来做的话，大概率也是一元一次方程，当然，也可能会被猜测成某个曲线函数。总之，我们会猜测它是某种函数形式。假如猜测它为一元一次方程\\(y = ax + b \\)，那么接下来的目标则是求解\\(a\\)与\\(b\\)的值，聪明的初中生会尽量选择一条穿过最多点的直线，来作为解，然后随便取穿过的两个点，套入方程，即可求得\\(a\\)与\\(b\\)的值。

这便是机器学习最简单的一个例子，当你去房产中介时，只需要告诉机器你房子的面积，便可以知道价格时，是不是就会觉得这台机器，稍微有那么一丢丢智能？而其原理，不过是初中生都可以做到的事情。

不过，要是想让机器来自动完成这件事，就不是那么方便了，让机器来完成的意义不仅在于方便人类偷懒，更在于人类的计算能力实在太低，当模型更复杂，数据量更大的时候，人类就无能为力了，因此必须让机器来自动完成这些工作。

接下来，真正开始介绍，如何让机器自动完成这些事，这才是机器学习的内容。

## 统计学习三要素

首先，我们需要将上述易懂的例子套入到接下来的各种术语概念中，以方便直观感受术语的意义，在后续的讨论中，直接使用术语，简化交流成本。

统计学习方法 = 模型 + 策略 + 算法

### 模型

统计学习方法首要面临的问题是：通过数据，我们期待它学出大概怎样的模型。以上面的例子，我们是期望它最终是，一元一次方程？还是二元一次方程？还是对数级函数？还是指数级函数等等。并且不同的模型会造成非常大的结果差异，例如，假如初中生猜测模型为二元一次方程，那么结果就很不靠谱，房价很少会因为面积增大而先降再升。

确定模型后，模型组成的空间则称作假设空间，假设空间中的模型一般有无穷个，以\\(y = ax + b \\)为例，\\(a\\)与\\(b\\)未确定之前，可以是平面中的任何直线。所以，任务就是当人类选择好了模型后，机器如何学习出一个好的参数。

除此之外，还要认识到一个正确的模型对机器学习来说有多么重要，所以机器学习的过程中，最好多尝试几种不同的模型。

为方便交流，使用\\(F\\)表示假设空间，如果目标是决策函数，那么假设空间可以表示为由一个参数向量决定的函数集合
$$F=\\{f|Y=f_\theta(X),\theta \in R^n\\}$$


### 策略

策略的作用则是当确定了模型后，按照什么依据来从无穷的假设空间中寻找到期望的那一个。还是以上个例子来讲，在确定\\(y = ax + b \\)模型后，其假设空间有无数个，如何找到我们期望的\\(f\\)，也就是如何求解最优的\\(a\\)与\\(b\\)呢，这时便依靠策略来求解了。在这个例子中，我们尝试画一条穿过最多点的直线来求解\\(a\\)与\\(b\\)，其数学含义则是利用了绝对损失函数，也是一种求解的策略之一。

所以策略其实也是一种函数，它的作用就是：当确定了假设空间\\(F\\)，也确定了某个\\(f_\theta(X)\\)后，怎么判断当前这个模型的好坏。

关于策略函数有两个概念，一个是损失函数，一个是风险函数。

* 损失函数：用来计算，当把模型应用到数据上时，真实结果和预期的差值。
	
	常见的损失函数有（\\(Y\\)为真实结果，\\(f(X)\\)为预测值）：
	* 0-1损失函数
	$$L(Y, f(X))=\begin{cases}
	1,\quad Y \neq f(X) \\\\
	0,\quad x = f(X)
	\end{cases}$$
	* 平方损失函数
	$$L(Y, f(X))=(Y - f(X))^2$$
	* 绝对损失函数
	$$L(Y, f(X))=|Y - f(X)|$$
	
* 风险函数：风险函数的作用是计算出损失函数的期望，称为期望损失：
	$$R_{exp}(f)=E\_{p}\begin{bmatrix}L(Y,f(X))\end{bmatrix}=\int\_{xy}L(y, f(x))P(x,y)dxdy$$
	需要注意，损失函数代表的是如何去衡量一个模型的好坏。损失函数的期望自然也就代表了这个模型的好坏。因此如果能直接计算出风险函数的值，那么就能知道模型的好坏，就能比较并选择出较好的模型。但是问题在于\\(P(x,y)\\)不可知，因此风险函数无法直接计算。
	
由于无法直接获得期望损失，也就无法知道这个模型的好坏。但一个很直观的想法是将所有已知数据套入损失函数，取平均为\\(R\_{emp}\\)，称为经验损失：
	$$R_{emp}=\frac{1}{N}\sum\_{i=1}^{n}L(y\_i, f(x\_i))$$
	
这里四个概念：损失函数、风险函数、期望损失、经验损失。千万不要混淆。

很明显，根据大数定律，如果样本数据量\\(N\\)趋向无穷时，经验损失也就慢慢逼近期望损失了。这是简单的做法，可以称为经验风险最小化。但是这个策略也存在一定的问题，因为真实世界的样本数量一般不会这么理想。由此衍生出结构风险最小化去帮助我们更好地选择\\(f\_{\theta}(x)\\)。

* 经验风险最小化：选择最小的\\(R\_{emp}\\)指示的\\(f\_{\theta}(x)\\)
$$min\;R_{emp}=\frac{1}{N}\sum\_{i=1}^{n}L(y\_i, f(x\_i))$$
* 结构风险最小化：引入正则化，帮助防止过拟合
$$min\;R_{emp}=\frac{1}{N}\sum\_{i=1}^{n}L(y\_i, f(x\_i))+\lambda J(f)$$

### 算法

算法的作用是：当我们有了上述各种函数，知道了目标模型的假设空间，知道了依据什么在假设空间中寻找模型，唯一差的就是具体的寻找过程了。寻找的过程无非就是计算的过程。对于我们的例子而言，一元一次方程有明显的解，因此直接就可以计算得到，而对于复杂的模型来说，或者是没有显示解的模型，还可以使用数值计算去不停的迭代计算。这些就都归属于算法步骤了。
